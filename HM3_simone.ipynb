{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 3, Text Mining an Information Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# totti\n",
    "testo1 = \"È stata Antonella Fiordelisi, concorrente del Grande Fratello Vip. A lanciare una bomba nel corso dell’ultima puntata del reality show condotto da Alfonso Signorini. “Totti mi ha scritto, mi ha mandato solo un messaggio.Aveva scritto ‘Ciao’. È accaduto qualche mese fa”, ha raccontato l’influencer, lanciando un assist al conduttore Alfonso Signorini che ha sottolineato il fatto che, se i tempi raccontati da Antonella corrispondessero al vero, il messaggio sarebbe arrivato quando l’ex capitano della Roma era già legato a Noemi Bocchi. A difendere Totti è arrivato l’amico Alex Nuccetelli secondo il quale quel messaggio sarebbe stato solo il frutto di un fraintendimento\"\n",
    "\n",
    "# totti 2\n",
    "testo2 = \"Eccolo l’ottavo re di Roma. Francesco Totti. Il Capitano. Uno dei giocatori più forti e pagati della storia del calcio italiano. Un campione diventato leggenda. Un mito indiscutibile, amato e osannato dai tifosi, ma ammirato anche dagli avversari. Una carriera unica e straordinaria per il numero 10, con 25 anni da giallorosso. Non ha mai conosciuto altra maglia e con la Roma ha segnato ben 307 gol. Il suo “cucchiaio” ha fatto storia. E anche ora che, il 28 maggio 2017 ha dato l’addio alla carriera di calciatore restando nella squadra come dirigente, Francesco è destinato a restare nel cuore di tutti. L’autobiografia “Un capitano” presentata al Colosseo il 27 settembre, giorno del suo 42° compleanno, racconta molto di lui. Ma siete sicuri di conoscerlo davvero? Ecco 10 cose che del Pupone non sapete\"\n",
    "\n",
    "# prof\n",
    "testo3 = \"Un insegnante di un istituto superiore di Pontedera, nel Pisano, è stato sospeso dopo avere colpito con un pugno allo stomaco uno studente che in quel momento si trovava vicino alla cattedra durante la lezione e lo stava deridendo. Sull'episodio, avvenuto nei giorni scorsi, indaga la polizia che ha ricevuto la denuncia da parte dei genitori del ragazzo mentre la dirigenza scolastica ha immediatamente sospeso il docente. La notizia è stata pubblicata oggi da Il Tirreno. C'è anche un video ad immortalare il pugno. Le immagini, di 14 secondi, sono state girate in classe dagli altri studenti con uno smartphone e immortalano la situazione di indisciplina conclusasi con lo scatto d'ira del professore. Il docente si volta di scatto verso l'alunno alle sue spalle, mentre lo starebbe deridendo, e lo raggiunge con un pugno allo stomaco prima di alzarsi e affrontarlo con aria di sfida. A questo punto il video si interrompe e sull'intero accaduto è chiamata a fare luce la polizia del commissariato che sta compiendo accertamenti.\"\n",
    "\n",
    "# meteo\n",
    "testo4 = \"E' arrivato un po' d'Autunno sul nostro Paese dopo un lunghissimo periodo contrassegnato dal bel tempo, ma soprattutto da un clima che di autunnale aveva davvero ben poco. Anzi, sul finire di Ottobre su alcune aree del Paese sembrava di essere tornati in piena Estate. Ora però le cose sono cambiate. Dal Nord Europa è sceso un freddo vortice ciclonico che sta tutt'ora attraversando da Nord a Sud tutto il nostro Paese e che ha già provocato una decisa metamorfosi sul fronte climatico soprattutto sulle regioni del Centro e del Nord. Ma le temperature saranno presto destinate a subire un bel crollo anche al Sud visto che il nocciolo del brutto tempo si andrà gradualmente a concentrare proprio sulle regioni meridionali. Ma la novità più clamorosa sta nel fatto che nelle prossime 24/48 ore il clima sull'Italia sarà destinato ad assumere ancora di più connotati autunnali, facendoci così dimenticare delle calde giornate di fine Ottobre.\"\n",
    "\n",
    "# steve jobs\n",
    "testo5 = \"Nello stesso anno Steve Jobs si iscrive al Reed College di Portland, specialmente per rivolgere l'attenzione alla sua principale passione, l'informatica, ma la via accademica non viene percorsa per molto tempo: dopo un semestre abbandona l'università ed inizia a lavorare in Atari come programmatore di videogames, perlomeno fino a quando raggiunge il quantitativo di denaro necessario per poter partire per un viaggio verso l'India.\"\n",
    "\n",
    "# gatti\n",
    "testo6 = \"In silenzio, in segreto e spesso di notte, l’antica guerra tra il gatto ed i roditori è continuata nel corso delle epoche. I piccoli felini rappresentavano un bastione di difesa contro i topi (principali divoratori delle stesse scorte alimentari umane) e contro le circa 35 malattie pericolose di cui sono portatori (tra cui il tifo e la peste bubbonica). Nel corso del tempo il loro ruolo di antagonisti delle malattie e della fame è stato in larga misura sostituito dalla medicina moderna, dalle strutture sanitarie pubbliche e dalla rivoluzione industriale nello stoccaggio e conservazione delle riserve alimentari.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import words  # riconosce le parole inglesi\n",
    "\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I try with a little text taken from internet\n",
    "\n",
    "text = \"As the story begins, Utterson and Enfield are taking their regular Sunday stroll and walking down a particularly prosperous-looking street. They come upon a neglected building, which seems out of place in the neighborhood, and Enfield relates a story in connection with it. Enfield was walking in the same neighborhood late one night, when he witnessed a shrunken, misshapen man crash into and trample a young girl. He collared the man before he could get away, and then brought him back to the girl, around whom an angry crowd had gathered. The captured man appeared so overwhelmingly ugly that the crowd immediately despised him. United, the crowd threatened to ruin the ugly man’s good name unless he did something to make amends; the man, seeing himself trapped, bought them off with one hundred pounds, which he obtained upon entering the neglected building through its only door. Strangely enough, the check bore the name of a very reputable man; furthermore, and in spite of Enfield’s suspicions, it proved to be legitimate and not a forgery. Enfield hypothesizes that the ugly culprit had somehow blackmailed the man whose name appeared on the check. Spurning gossip, however, Enfield refuses to reveal that name.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As the story begins  Utterson and Enfield are taking their regular Sunday stroll and walking down a particularly prosperous looking street  They come upon a neglected building  which seems out of place in the neighborhood  and Enfield relates a story in connection with it  Enfield was walking in the same neighborhood late one night  when he witnessed a shrunken  misshapen man crash into and trample a young girl  He collared the man before he could get away  and then brought him back to the girl  around whom an angry crowd had gathered  The captured man appeared so overwhelmingly ugly that the crowd immediately despised him  United  the crowd threatened to ruin the ugly man s good name unless he did something to make amends  the man  seeing himself trapped  bought them off with one hundred pounds  which he obtained upon entering the neglected building through its only door  Strangely enough  the check bore the name of a very reputable man  furthermore  and in spite of Enfield s suspicions  it proved to be legitimate and not a forgery  Enfield hypothesizes that the ugly culprit had somehow blackmailed the man whose name appeared on the check  Spurning gossip  however  Enfield refuses to reveal that name \n"
     ]
    }
   ],
   "source": [
    "# First thing we have to do is cleaning the text from punctuation marks. We use regular expression to do this:\n",
    "import re\n",
    "\n",
    "expression = r'[^\\w\\s]'  # every thing that is not a word charachter or a space charachter \n",
    "cleaned_text = re.sub(expression, ' ', text) # substitute non-word charachters and non-sapec charachters\n",
    "print(cleaned_text) # output the \"cleaned\" text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/simonefacchiano/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/simonefacchiano/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/simonefacchiano/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Then, we can tokenize the text. Altough sometimes we may want a 'sentence tokenization', let'go for a word tokenization:\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['as',\n",
       " 'the',\n",
       " 'story',\n",
       " 'begins',\n",
       " 'utterson',\n",
       " 'and',\n",
       " 'enfield',\n",
       " 'are',\n",
       " 'taking',\n",
       " 'their',\n",
       " 'regular',\n",
       " 'sunday',\n",
       " 'stroll',\n",
       " 'and',\n",
       " 'walking',\n",
       " 'down',\n",
       " 'a',\n",
       " 'particularly',\n",
       " 'prosperous',\n",
       " 'looking',\n",
       " 'street',\n",
       " 'they',\n",
       " 'come',\n",
       " 'upon',\n",
       " 'a',\n",
       " 'neglected',\n",
       " 'building',\n",
       " 'which',\n",
       " 'seems',\n",
       " 'out',\n",
       " 'of',\n",
       " 'place',\n",
       " 'in',\n",
       " 'the',\n",
       " 'neighborhood',\n",
       " 'and',\n",
       " 'enfield',\n",
       " 'relates',\n",
       " 'a',\n",
       " 'story',\n",
       " 'in',\n",
       " 'connection',\n",
       " 'with',\n",
       " 'it',\n",
       " 'enfield',\n",
       " 'was',\n",
       " 'walking',\n",
       " 'in',\n",
       " 'the',\n",
       " 'same',\n",
       " 'neighborhood',\n",
       " 'late',\n",
       " 'one',\n",
       " 'night',\n",
       " 'when',\n",
       " 'he',\n",
       " 'witnessed',\n",
       " 'a',\n",
       " 'shrunken',\n",
       " 'misshapen',\n",
       " 'man',\n",
       " 'crash',\n",
       " 'into',\n",
       " 'and',\n",
       " 'trample',\n",
       " 'a',\n",
       " 'young',\n",
       " 'girl',\n",
       " 'he',\n",
       " 'collared',\n",
       " 'the',\n",
       " 'man',\n",
       " 'before',\n",
       " 'he',\n",
       " 'could',\n",
       " 'get',\n",
       " 'away',\n",
       " 'and',\n",
       " 'then',\n",
       " 'brought',\n",
       " 'him',\n",
       " 'back',\n",
       " 'to',\n",
       " 'the',\n",
       " 'girl',\n",
       " 'around',\n",
       " 'whom',\n",
       " 'an',\n",
       " 'angry',\n",
       " 'crowd',\n",
       " 'had',\n",
       " 'gathered',\n",
       " 'the',\n",
       " 'captured',\n",
       " 'man',\n",
       " 'appeared',\n",
       " 'so',\n",
       " 'overwhelmingly',\n",
       " 'ugly',\n",
       " 'that',\n",
       " 'the',\n",
       " 'crowd',\n",
       " 'immediately',\n",
       " 'despised',\n",
       " 'him',\n",
       " 'united',\n",
       " 'the',\n",
       " 'crowd',\n",
       " 'threatened',\n",
       " 'to',\n",
       " 'ruin',\n",
       " 'the',\n",
       " 'ugly',\n",
       " 'man',\n",
       " 's',\n",
       " 'good',\n",
       " 'name',\n",
       " 'unless',\n",
       " 'he',\n",
       " 'did',\n",
       " 'something',\n",
       " 'to',\n",
       " 'make',\n",
       " 'amends',\n",
       " 'the',\n",
       " 'man',\n",
       " 'seeing',\n",
       " 'himself',\n",
       " 'trapped',\n",
       " 'bought',\n",
       " 'them',\n",
       " 'off',\n",
       " 'with',\n",
       " 'one',\n",
       " 'hundred',\n",
       " 'pounds',\n",
       " 'which',\n",
       " 'he',\n",
       " 'obtained',\n",
       " 'upon',\n",
       " 'entering',\n",
       " 'the',\n",
       " 'neglected',\n",
       " 'building',\n",
       " 'through',\n",
       " 'its',\n",
       " 'only',\n",
       " 'door',\n",
       " 'strangely',\n",
       " 'enough',\n",
       " 'the',\n",
       " 'check',\n",
       " 'bore',\n",
       " 'the',\n",
       " 'name',\n",
       " 'of',\n",
       " 'a',\n",
       " 'very',\n",
       " 'reputable',\n",
       " 'man',\n",
       " 'furthermore',\n",
       " 'and',\n",
       " 'in',\n",
       " 'spite',\n",
       " 'of',\n",
       " 'enfield',\n",
       " 's',\n",
       " 'suspicions',\n",
       " 'it',\n",
       " 'proved',\n",
       " 'to',\n",
       " 'be',\n",
       " 'legitimate',\n",
       " 'and',\n",
       " 'not',\n",
       " 'a',\n",
       " 'forgery',\n",
       " 'enfield',\n",
       " 'hypothesizes',\n",
       " 'that',\n",
       " 'the',\n",
       " 'ugly',\n",
       " 'culprit',\n",
       " 'had',\n",
       " 'somehow',\n",
       " 'blackmailed',\n",
       " 'the',\n",
       " 'man',\n",
       " 'whose',\n",
       " 'name',\n",
       " 'appeared',\n",
       " 'on',\n",
       " 'the',\n",
       " 'check',\n",
       " 'spurning',\n",
       " 'gossip',\n",
       " 'however',\n",
       " 'enfield',\n",
       " 'refuses',\n",
       " 'to',\n",
       " 'reveal',\n",
       " 'that',\n",
       " 'name']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we lower the text:\n",
    "cleaned_text = cleaned_text.lower()\n",
    "\n",
    "text_tokenize = nltk.word_tokenize(cleaned_text)\n",
    "text_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['story',\n",
       " 'begins',\n",
       " 'utterson',\n",
       " 'enfield',\n",
       " 'taking',\n",
       " 'regular',\n",
       " 'sunday',\n",
       " 'stroll',\n",
       " 'walking',\n",
       " 'particularly',\n",
       " 'prosperous',\n",
       " 'looking',\n",
       " 'street',\n",
       " 'come',\n",
       " 'upon',\n",
       " 'neglected',\n",
       " 'building',\n",
       " 'seems',\n",
       " 'place',\n",
       " 'neighborhood',\n",
       " 'enfield',\n",
       " 'relates',\n",
       " 'story',\n",
       " 'connection',\n",
       " 'enfield',\n",
       " 'walking',\n",
       " 'neighborhood',\n",
       " 'late',\n",
       " 'one',\n",
       " 'night',\n",
       " 'witnessed',\n",
       " 'shrunken',\n",
       " 'misshapen',\n",
       " 'man',\n",
       " 'crash',\n",
       " 'trample',\n",
       " 'young',\n",
       " 'girl',\n",
       " 'collared',\n",
       " 'man',\n",
       " 'could',\n",
       " 'get',\n",
       " 'away',\n",
       " 'brought',\n",
       " 'back',\n",
       " 'girl',\n",
       " 'around',\n",
       " 'angry',\n",
       " 'crowd',\n",
       " 'gathered',\n",
       " 'captured',\n",
       " 'man',\n",
       " 'appeared',\n",
       " 'overwhelmingly',\n",
       " 'ugly',\n",
       " 'crowd',\n",
       " 'immediately',\n",
       " 'despised',\n",
       " 'united',\n",
       " 'crowd',\n",
       " 'threatened',\n",
       " 'ruin',\n",
       " 'ugly',\n",
       " 'man',\n",
       " 'good',\n",
       " 'name',\n",
       " 'unless',\n",
       " 'something',\n",
       " 'make',\n",
       " 'amends',\n",
       " 'man',\n",
       " 'seeing',\n",
       " 'trapped',\n",
       " 'bought',\n",
       " 'one',\n",
       " 'hundred',\n",
       " 'pounds',\n",
       " 'obtained',\n",
       " 'upon',\n",
       " 'entering',\n",
       " 'neglected',\n",
       " 'building',\n",
       " 'door',\n",
       " 'strangely',\n",
       " 'enough',\n",
       " 'check',\n",
       " 'bore',\n",
       " 'name',\n",
       " 'reputable',\n",
       " 'man',\n",
       " 'furthermore',\n",
       " 'spite',\n",
       " 'enfield',\n",
       " 'suspicions',\n",
       " 'proved',\n",
       " 'legitimate',\n",
       " 'forgery',\n",
       " 'enfield',\n",
       " 'hypothesizes',\n",
       " 'ugly',\n",
       " 'culprit',\n",
       " 'somehow',\n",
       " 'blackmailed',\n",
       " 'man',\n",
       " 'whose',\n",
       " 'name',\n",
       " 'appeared',\n",
       " 'check',\n",
       " 'spurning',\n",
       " 'gossip',\n",
       " 'however',\n",
       " 'enfield',\n",
       " 'refuses',\n",
       " 'reveal',\n",
       " 'name']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we have the list of words, let's remove stop words (aka the words that do not contain any 'important' information)\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = stopwords.words('english')  # list of stopwords\n",
    "#print(stopwords)  # id you need to print the list of words you're going to delete\n",
    "#stopwords = stopwords.append('a')  # to add a stopword to the list\n",
    "\n",
    "text_tokenize_no_stopwords = [word for word in text_tokenize if not word in stopwords]\n",
    "text_tokenize_no_stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we would have Stemming, but we can skip to Lemmatization\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['story',\n",
       " 'begin',\n",
       " 'utterson',\n",
       " 'enfield',\n",
       " 'taking',\n",
       " 'regular',\n",
       " 'sunday',\n",
       " 'stroll',\n",
       " 'walking',\n",
       " 'particularly',\n",
       " 'prosperous',\n",
       " 'looking',\n",
       " 'street',\n",
       " 'come',\n",
       " 'upon',\n",
       " 'neglected',\n",
       " 'building',\n",
       " 'seems',\n",
       " 'place',\n",
       " 'neighborhood',\n",
       " 'enfield',\n",
       " 'relates',\n",
       " 'story',\n",
       " 'connection',\n",
       " 'enfield',\n",
       " 'walking',\n",
       " 'neighborhood',\n",
       " 'late',\n",
       " 'one',\n",
       " 'night',\n",
       " 'witnessed',\n",
       " 'shrunken',\n",
       " 'misshapen',\n",
       " 'man',\n",
       " 'crash',\n",
       " 'trample',\n",
       " 'young',\n",
       " 'girl',\n",
       " 'collared',\n",
       " 'man',\n",
       " 'could',\n",
       " 'get',\n",
       " 'away',\n",
       " 'brought',\n",
       " 'back',\n",
       " 'girl',\n",
       " 'around',\n",
       " 'angry',\n",
       " 'crowd',\n",
       " 'gathered',\n",
       " 'captured',\n",
       " 'man',\n",
       " 'appeared',\n",
       " 'overwhelmingly',\n",
       " 'ugly',\n",
       " 'crowd',\n",
       " 'immediately',\n",
       " 'despised',\n",
       " 'united',\n",
       " 'crowd',\n",
       " 'threatened',\n",
       " 'ruin',\n",
       " 'ugly',\n",
       " 'man',\n",
       " 'good',\n",
       " 'name',\n",
       " 'unless',\n",
       " 'something',\n",
       " 'make',\n",
       " 'amends',\n",
       " 'man',\n",
       " 'seeing',\n",
       " 'trapped',\n",
       " 'bought',\n",
       " 'one',\n",
       " 'hundred',\n",
       " 'pound',\n",
       " 'obtained',\n",
       " 'upon',\n",
       " 'entering',\n",
       " 'neglected',\n",
       " 'building',\n",
       " 'door',\n",
       " 'strangely',\n",
       " 'enough',\n",
       " 'check',\n",
       " 'bore',\n",
       " 'name',\n",
       " 'reputable',\n",
       " 'man',\n",
       " 'furthermore',\n",
       " 'spite',\n",
       " 'enfield',\n",
       " 'suspicion',\n",
       " 'proved',\n",
       " 'legitimate',\n",
       " 'forgery',\n",
       " 'enfield',\n",
       " 'hypothesizes',\n",
       " 'ugly',\n",
       " 'culprit',\n",
       " 'somehow',\n",
       " 'blackmailed',\n",
       " 'man',\n",
       " 'whose',\n",
       " 'name',\n",
       " 'appeared',\n",
       " 'check',\n",
       " 'spurning',\n",
       " 'gossip',\n",
       " 'however',\n",
       " 'enfield',\n",
       " 'refuse',\n",
       " 'reveal',\n",
       " 'name']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "lemmatized_text = []\n",
    "\n",
    "for word in text_tokenize_no_stopwords:\n",
    "    lemmatized_text.append(lemmatizer.lemmatize(word)) \n",
    "lemmatized_text    \n",
    "\n",
    "# Note: if we want stemming:\n",
    "# from nltk.stem import Port Stemmer\n",
    "# ...\n",
    "# PorterStemmer().stem(word)  # and you're done\n",
    "\n",
    "# End of Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'man': 7, 'enfield': 6, 'name': 4, 'crowd': 3, 'ugly': 3, 'story': 2, 'walking': 2, 'upon': 2, 'neglected': 2, 'building': 2, 'neighborhood': 2, 'one': 2, 'girl': 2, 'appeared': 2, 'check': 2, 'begin': 1, 'utterson': 1, 'taking': 1, 'regular': 1, 'sunday': 1, 'stroll': 1, 'particularly': 1, 'prosperous': 1, 'looking': 1, 'street': 1, 'come': 1, 'seems': 1, 'place': 1, 'relates': 1, 'connection': 1, 'late': 1, 'night': 1, 'witnessed': 1, 'shrunken': 1, 'misshapen': 1, 'crash': 1, 'trample': 1, 'young': 1, 'collared': 1, 'could': 1, 'get': 1, 'away': 1, 'brought': 1, 'back': 1, 'around': 1, 'angry': 1, 'gathered': 1, 'captured': 1, 'overwhelmingly': 1, 'immediately': 1, 'despised': 1, 'united': 1, 'threatened': 1, 'ruin': 1, 'good': 1, 'unless': 1, 'something': 1, 'make': 1, 'amends': 1, 'seeing': 1, 'trapped': 1, 'bought': 1, 'hundred': 1, 'pound': 1, 'obtained': 1, 'entering': 1, 'door': 1, 'strangely': 1, 'enough': 1, 'bore': 1, 'reputable': 1, 'furthermore': 1, 'spite': 1, 'suspicion': 1, 'proved': 1, 'legitimate': 1, 'forgery': 1, 'hypothesizes': 1, 'culprit': 1, 'somehow': 1, 'blackmailed': 1, 'whose': 1, 'spurning': 1, 'gossip': 1, 'however': 1, 'refuse': 1, 'reveal': 1})\n"
     ]
    }
   ],
   "source": [
    "# Now we can start thinking about some metrics. For example we can compute the frequencies of the words.\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "counter_words = Counter(lemmatized_text)\n",
    "\n",
    "print(counter_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>begin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>utterson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enfield</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>taking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>spurning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>gossip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>however</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>refuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>reveal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "Index          \n",
       "1         story\n",
       "2         begin\n",
       "3      utterson\n",
       "4       enfield\n",
       "5        taking\n",
       "...         ...\n",
       "83     spurning\n",
       "84       gossip\n",
       "85      however\n",
       "86       refuse\n",
       "87       reveal\n",
       "\n",
       "[87 rows x 1 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now. Ley's start with serious things.\n",
    "# We want to assign each word of a given text a unique index. In the HW we deal with mutliple texts: here we focus on just one text, but it is the same thing.\n",
    "\n",
    "# We create a dataset. The first column will be a column of indexes. The second column contains the words.\n",
    "# Let's start from the second column:\n",
    "\n",
    "counter_words_list = list(counter_words)\n",
    "\n",
    "indexes = list(range(1, len(counter_words_list)+1))\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(counter_words_list)\n",
    "df.insert(1, \"Index\", indexes, True)\n",
    "df = df.set_index('Index')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>utterson</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "Index          \n",
       "3      utterson"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[[3]]  # for selecting the word based on the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>placeName</th>\n",
       "      <th>placeTags</th>\n",
       "      <th>numPeopleVisited</th>\n",
       "      <th>numPeopleWant</th>\n",
       "      <th>placeDesc</th>\n",
       "      <th>placeShortDesc</th>\n",
       "      <th>placeNearby</th>\n",
       "      <th>placeAddress</th>\n",
       "      <th>placeAlt</th>\n",
       "      <th>placeLong</th>\n",
       "      <th>placeEditors</th>\n",
       "      <th>placePubDate</th>\n",
       "      <th>placeRelatedLists</th>\n",
       "      <th>placeRelatedPlaces</th>\n",
       "      <th>placeURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catacombes de Paris</td>\n",
       "      <td>['ossuaries', 'memento mori', 'catacombs and c...</td>\n",
       "      <td>4445</td>\n",
       "      <td>7045</td>\n",
       "      <td>In 2004, Parisian police were assigned to do a...</td>\n",
       "      <td>The vast, legendary catacombs hold secrets muc...</td>\n",
       "      <td>['Sculptures de Décure 0.04 miles', 'Arago Med...</td>\n",
       "      <td>1 Place Denfert-RochereauParis, 75014France</td>\n",
       "      <td>48.8343</td>\n",
       "      <td>2.3322</td>\n",
       "      <td>['CPilgrim', 'marypippen', 'ramonrodz2212', 'm...</td>\n",
       "      <td>2009-02-13</td>\n",
       "      <td>['19 Catacombs Sure to Tingle Your Spine', \"Th...</td>\n",
       "      <td>['Ossario di San Martino', 'Leuk Charnel House...</td>\n",
       "      <td>https://www.atlasobscura.com/places/catacombes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City Hall Station</td>\n",
       "      <td>['subways', 'subterranean', 'infrastructure', ...</td>\n",
       "      <td>1828</td>\n",
       "      <td>8580</td>\n",
       "      <td>The first New York City subway was built and o...</td>\n",
       "      <td>A beautiful and abandoned New York subway stat...</td>\n",
       "      <td>['African Burial Ground National Monument 0.08...</td>\n",
       "      <td>31 Centre StNew York, New York, 10007United St...</td>\n",
       "      <td>40.7134</td>\n",
       "      <td>-74.0046</td>\n",
       "      <td>['Rebekah Otto', 'charding407', 'fosterc827', ...</td>\n",
       "      <td>2010-05-08</td>\n",
       "      <td>['30 Unexpected Places to Have a Joyful Advent...</td>\n",
       "      <td>['Crystal Palace Subway', 'Moscow Metro Statio...</td>\n",
       "      <td>https://www.atlasobscura.com/places/city-hall-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dream House</td>\n",
       "      <td>['optical oddities', 'eccentric homes', 'music...</td>\n",
       "      <td>765</td>\n",
       "      <td>5993</td>\n",
       "      <td>When walking down Church Street in Tribeca, ke...</td>\n",
       "      <td>La Monte Young and Marian Zazeela's \"Dream Hou...</td>\n",
       "      <td>['Aretha Franklin Subway Tributes 0.11 miles',...</td>\n",
       "      <td>275 Church StNew York, New York, 10013United S...</td>\n",
       "      <td>40.7185</td>\n",
       "      <td>-74.0048</td>\n",
       "      <td>['seanmattison', 'Gray', 'imluvnlyf', 'erosika...</td>\n",
       "      <td>2009-09-22</td>\n",
       "      <td>['30 Unexpected Places to Have a Joyful Advent...</td>\n",
       "      <td>['Callejon de Hamel', 'Casa Neverlandia', 'Cas...</td>\n",
       "      <td>https://www.atlasobscura.com/places/dream-house</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             placeName                                          placeTags  \\\n",
       "0  Catacombes de Paris  ['ossuaries', 'memento mori', 'catacombs and c...   \n",
       "1    City Hall Station  ['subways', 'subterranean', 'infrastructure', ...   \n",
       "2          Dream House  ['optical oddities', 'eccentric homes', 'music...   \n",
       "\n",
       "   numPeopleVisited  numPeopleWant  \\\n",
       "0              4445           7045   \n",
       "1              1828           8580   \n",
       "2               765           5993   \n",
       "\n",
       "                                           placeDesc  \\\n",
       "0  In 2004, Parisian police were assigned to do a...   \n",
       "1  The first New York City subway was built and o...   \n",
       "2  When walking down Church Street in Tribeca, ke...   \n",
       "\n",
       "                                      placeShortDesc  \\\n",
       "0  The vast, legendary catacombs hold secrets muc...   \n",
       "1  A beautiful and abandoned New York subway stat...   \n",
       "2  La Monte Young and Marian Zazeela's \"Dream Hou...   \n",
       "\n",
       "                                         placeNearby  \\\n",
       "0  ['Sculptures de Décure 0.04 miles', 'Arago Med...   \n",
       "1  ['African Burial Ground National Monument 0.08...   \n",
       "2  ['Aretha Franklin Subway Tributes 0.11 miles',...   \n",
       "\n",
       "                                        placeAddress  placeAlt  placeLong  \\\n",
       "0        1 Place Denfert-RochereauParis, 75014France   48.8343     2.3322   \n",
       "1  31 Centre StNew York, New York, 10007United St...   40.7134   -74.0046   \n",
       "2  275 Church StNew York, New York, 10013United S...   40.7185   -74.0048   \n",
       "\n",
       "                                        placeEditors placePubDate  \\\n",
       "0  ['CPilgrim', 'marypippen', 'ramonrodz2212', 'm...   2009-02-13   \n",
       "1  ['Rebekah Otto', 'charding407', 'fosterc827', ...   2010-05-08   \n",
       "2  ['seanmattison', 'Gray', 'imluvnlyf', 'erosika...   2009-09-22   \n",
       "\n",
       "                                   placeRelatedLists  \\\n",
       "0  ['19 Catacombs Sure to Tingle Your Spine', \"Th...   \n",
       "1  ['30 Unexpected Places to Have a Joyful Advent...   \n",
       "2  ['30 Unexpected Places to Have a Joyful Advent...   \n",
       "\n",
       "                                  placeRelatedPlaces  \\\n",
       "0  ['Ossario di San Martino', 'Leuk Charnel House...   \n",
       "1  ['Crystal Palace Subway', 'Moscow Metro Statio...   \n",
       "2  ['Callejon de Hamel', 'Casa Neverlandia', 'Cas...   \n",
       "\n",
       "                                            placeURL  \n",
       "0  https://www.atlasobscura.com/places/catacombes...  \n",
       "1  https://www.atlasobscura.com/places/city-hall-...  \n",
       "2    https://www.atlasobscura.com/places/dream-house  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Download the tsv fil with all the info\n",
    "dataset=pd.read_csv('/Users/simonefacchiano/Desktop/Data Science/ADM/Dataset.tsv', sep='\\t')\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>placeName</th>\n",
       "      <th>placeTags</th>\n",
       "      <th>numPeopleVisited</th>\n",
       "      <th>numPeopleWant</th>\n",
       "      <th>placeDesc</th>\n",
       "      <th>placeShortDesc</th>\n",
       "      <th>placeNearby</th>\n",
       "      <th>placeAddress</th>\n",
       "      <th>placeAlt</th>\n",
       "      <th>placeLong</th>\n",
       "      <th>placeEditors</th>\n",
       "      <th>placePubDate</th>\n",
       "      <th>placeRelatedLists</th>\n",
       "      <th>placeRelatedPlaces</th>\n",
       "      <th>placeURL</th>\n",
       "      <th>Processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catacombes de Paris</td>\n",
       "      <td>['ossuaries', 'memento mori', 'catacombs and c...</td>\n",
       "      <td>4445</td>\n",
       "      <td>7045</td>\n",
       "      <td>In 2004, Parisian police were assigned to do a...</td>\n",
       "      <td>The vast, legendary catacombs hold secrets muc...</td>\n",
       "      <td>['Sculptures de Décure 0.04 miles', 'Arago Med...</td>\n",
       "      <td>1 Place Denfert-RochereauParis, 75014France</td>\n",
       "      <td>48.8343</td>\n",
       "      <td>2.3322</td>\n",
       "      <td>['CPilgrim', 'marypippen', 'ramonrodz2212', 'm...</td>\n",
       "      <td>2009-02-13</td>\n",
       "      <td>['19 Catacombs Sure to Tingle Your Spine', \"Th...</td>\n",
       "      <td>['Ossario di San Martino', 'Leuk Charnel House...</td>\n",
       "      <td>https://www.atlasobscura.com/places/catacombes...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             placeName                                          placeTags  \\\n",
       "0  Catacombes de Paris  ['ossuaries', 'memento mori', 'catacombs and c...   \n",
       "\n",
       "   numPeopleVisited  numPeopleWant  \\\n",
       "0              4445           7045   \n",
       "\n",
       "                                           placeDesc  \\\n",
       "0  In 2004, Parisian police were assigned to do a...   \n",
       "\n",
       "                                      placeShortDesc  \\\n",
       "0  The vast, legendary catacombs hold secrets muc...   \n",
       "\n",
       "                                         placeNearby  \\\n",
       "0  ['Sculptures de Décure 0.04 miles', 'Arago Med...   \n",
       "\n",
       "                                  placeAddress  placeAlt  placeLong  \\\n",
       "0  1 Place Denfert-RochereauParis, 75014France   48.8343     2.3322   \n",
       "\n",
       "                                        placeEditors placePubDate  \\\n",
       "0  ['CPilgrim', 'marypippen', 'ramonrodz2212', 'm...   2009-02-13   \n",
       "\n",
       "                                   placeRelatedLists  \\\n",
       "0  ['19 Catacombs Sure to Tingle Your Spine', \"Th...   \n",
       "\n",
       "                                  placeRelatedPlaces  \\\n",
       "0  ['Ossario di San Martino', 'Leuk Charnel House...   \n",
       "\n",
       "                                            placeURL Processed  \n",
       "0  https://www.atlasobscura.com/places/catacombes...      None  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a new column, filled by 'cleaned' descriptions (no punctuation, tokenization, lemmatization).\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "processed = []\n",
    "dataset['Processed'] = None\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    small_processed = []\n",
    "    sentence = row['placeDesc'].lower()\n",
    "    sentence = re.sub(r'[^\\w\\s]', ' ', sentence)\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    words = [w for w in words if not w in stopwords]\n",
    "    for word in words:\n",
    "        small_processed.append(lemmatizer.lemmatize(word))\n",
    "\n",
    "    processed.append(small_processed)\n",
    "    \n",
    "dataset['Processed'] = processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>placeName</th>\n",
       "      <th>placeTags</th>\n",
       "      <th>numPeopleVisited</th>\n",
       "      <th>numPeopleWant</th>\n",
       "      <th>placeDesc</th>\n",
       "      <th>placeShortDesc</th>\n",
       "      <th>placeNearby</th>\n",
       "      <th>placeAddress</th>\n",
       "      <th>placeAlt</th>\n",
       "      <th>placeLong</th>\n",
       "      <th>placeEditors</th>\n",
       "      <th>placePubDate</th>\n",
       "      <th>placeRelatedLists</th>\n",
       "      <th>placeRelatedPlaces</th>\n",
       "      <th>placeURL</th>\n",
       "      <th>Processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Catacombes de Paris</td>\n",
       "      <td>['ossuaries', 'memento mori', 'catacombs and c...</td>\n",
       "      <td>4445</td>\n",
       "      <td>7045</td>\n",
       "      <td>In 2004, Parisian police were assigned to do a...</td>\n",
       "      <td>The vast, legendary catacombs hold secrets muc...</td>\n",
       "      <td>['Sculptures de Décure 0.04 miles', 'Arago Med...</td>\n",
       "      <td>1 Place Denfert-RochereauParis, 75014France</td>\n",
       "      <td>48.8343</td>\n",
       "      <td>2.3322</td>\n",
       "      <td>['CPilgrim', 'marypippen', 'ramonrodz2212', 'm...</td>\n",
       "      <td>2009-02-13</td>\n",
       "      <td>['19 Catacombs Sure to Tingle Your Spine', \"Th...</td>\n",
       "      <td>['Ossario di San Martino', 'Leuk Charnel House...</td>\n",
       "      <td>https://www.atlasobscura.com/places/catacombes...</td>\n",
       "      <td>[2004, parisian, police, assigned, training, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>City Hall Station</td>\n",
       "      <td>['subways', 'subterranean', 'infrastructure', ...</td>\n",
       "      <td>1828</td>\n",
       "      <td>8580</td>\n",
       "      <td>The first New York City subway was built and o...</td>\n",
       "      <td>A beautiful and abandoned New York subway stat...</td>\n",
       "      <td>['African Burial Ground National Monument 0.08...</td>\n",
       "      <td>31 Centre StNew York, New York, 10007United St...</td>\n",
       "      <td>40.7134</td>\n",
       "      <td>-74.0046</td>\n",
       "      <td>['Rebekah Otto', 'charding407', 'fosterc827', ...</td>\n",
       "      <td>2010-05-08</td>\n",
       "      <td>['30 Unexpected Places to Have a Joyful Advent...</td>\n",
       "      <td>['Crystal Palace Subway', 'Moscow Metro Statio...</td>\n",
       "      <td>https://www.atlasobscura.com/places/city-hall-...</td>\n",
       "      <td>[first, new, york, city, subway, built, operat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             placeName                                          placeTags  \\\n",
       "0  Catacombes de Paris  ['ossuaries', 'memento mori', 'catacombs and c...   \n",
       "1    City Hall Station  ['subways', 'subterranean', 'infrastructure', ...   \n",
       "\n",
       "   numPeopleVisited  numPeopleWant  \\\n",
       "0              4445           7045   \n",
       "1              1828           8580   \n",
       "\n",
       "                                           placeDesc  \\\n",
       "0  In 2004, Parisian police were assigned to do a...   \n",
       "1  The first New York City subway was built and o...   \n",
       "\n",
       "                                      placeShortDesc  \\\n",
       "0  The vast, legendary catacombs hold secrets muc...   \n",
       "1  A beautiful and abandoned New York subway stat...   \n",
       "\n",
       "                                         placeNearby  \\\n",
       "0  ['Sculptures de Décure 0.04 miles', 'Arago Med...   \n",
       "1  ['African Burial Ground National Monument 0.08...   \n",
       "\n",
       "                                        placeAddress  placeAlt  placeLong  \\\n",
       "0        1 Place Denfert-RochereauParis, 75014France   48.8343     2.3322   \n",
       "1  31 Centre StNew York, New York, 10007United St...   40.7134   -74.0046   \n",
       "\n",
       "                                        placeEditors placePubDate  \\\n",
       "0  ['CPilgrim', 'marypippen', 'ramonrodz2212', 'm...   2009-02-13   \n",
       "1  ['Rebekah Otto', 'charding407', 'fosterc827', ...   2010-05-08   \n",
       "\n",
       "                                   placeRelatedLists  \\\n",
       "0  ['19 Catacombs Sure to Tingle Your Spine', \"Th...   \n",
       "1  ['30 Unexpected Places to Have a Joyful Advent...   \n",
       "\n",
       "                                  placeRelatedPlaces  \\\n",
       "0  ['Ossario di San Martino', 'Leuk Charnel House...   \n",
       "1  ['Crystal Palace Subway', 'Moscow Metro Statio...   \n",
       "\n",
       "                                            placeURL  \\\n",
       "0  https://www.atlasobscura.com/places/catacombes...   \n",
       "1  https://www.atlasobscura.com/places/city-hall-...   \n",
       "\n",
       "                                           Processed  \n",
       "0  [2004, parisian, police, assigned, training, e...  \n",
       "1  [first, new, york, city, subway, built, operat...  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can do the real 2.1.1)\n",
    "# What we need to do is to create a dictionary containing all the words of the description, where:\n",
    "# { key = word : value = [docs containing the word] }\n",
    "\n",
    "# So, first we crate a list containing all the words:\n",
    "import numpy as np\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    for w in row['Processed']:\n",
    "        if w not in all_words:\n",
    "            all_words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50737"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_words)  # so, in total, we have 50k+ words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/simonefacchiano/Desktop/Data Science/ADM/provahm3.ipynb Cella 24\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simonefacchiano/Desktop/Data%20Science/ADM/provahm3.ipynb#X55sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m lista \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simonefacchiano/Desktop/Data%20Science/ADM/provahm3.ipynb#X55sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m index, row \u001b[39min\u001b[39;00m dataset\u001b[39m.\u001b[39miterrows():\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/simonefacchiano/Desktop/Data%20Science/ADM/provahm3.ipynb#X55sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mif\u001b[39;00m w \u001b[39min\u001b[39;00m row[\u001b[39m'\u001b[39;49m\u001b[39mProcessed\u001b[39;49m\u001b[39m'\u001b[39;49m]:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simonefacchiano/Desktop/Data%20Science/ADM/provahm3.ipynb#X55sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         lista \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mappend(lista, w)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/simonefacchiano/Desktop/Data%20Science/ADM/provahm3.ipynb#X55sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m np\u001b[39m.\u001b[39mappend(cont_docs, lista)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:958\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    955\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    957\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 958\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    960\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    961\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    962\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now, for each word in all_words, we want to associate a list of docs that contain that particular word:\n",
    "cont_docs = np.array([])\n",
    "\n",
    "for w in all_words:\n",
    "    lista = np.array([])\n",
    "    for index, row in dataset.iterrows():\n",
    "        if w in row['Processed']:\n",
    "            lista = np.append(lista, w)\n",
    "    np.append(cont_docs, lista)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c' 'i' 'a' 'o' ' ' 'c' 'o' 'm' 'e' ' ' 'v' 'a']\n"
     ]
    }
   ],
   "source": [
    "# Too slow. I try with numpy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "#cont_docs2 = []\n",
    "cont_docs2 = np.array([])\n",
    "lettere = 'ciao come va'\n",
    "\n",
    "for l in lettere:\n",
    "    cont_docs2 = np.append(cont_docs2, l)\n",
    "\n",
    "print(cont_docs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Altro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stopwords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/simonefacchiano/Desktop/Data Science/ADM/provahm3.ipynb Cella 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/simonefacchiano/Desktop/Data%20Science/ADM/provahm3.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m stop_words \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(stopwords\u001b[39m.\u001b[39mwords(\u001b[39m'\u001b[39m\u001b[39mitalian\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stopwords' is not defined"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('italian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stata', 'antonella', 'fiordelisi', 'concorrente', 'grande', 'fratello', 'vip', 'lanciare', 'bomba', 'corso', 'ultima', 'puntata', 'reality', 'show', 'condotto', 'alfonso', 'signorini', 'totti', 'scritto', 'mandato', 'solo', 'messaggio', 'scritto', 'ciao', 'accaduto', 'qualche', 'mese', 'fa', 'raccontato', 'influencer', 'lanciando', 'assist', 'conduttore', 'alfonso', 'signorini', 'sottolineato', 'fatto', 'tempi', 'raccontati', 'antonella', 'corrispondessero', 'vero', 'messaggio', 'arrivato', 'quando', 'ex', 'capitano', 'roma', 'già', 'legato', 'noemi', 'bocchi', 'difendere', 'totti', 'arrivato', 'amico', 'alex', 'nuccetelli', 'secondo', 'quel', 'messaggio', 'stato', 'solo', 'frutto', 'fraintendimento']\n",
      "************************************************************************************************************************************************************\n",
      "************************************************************************************************************************************************************\n",
      "Counter({'messaggio': 3, 'antonella': 2, 'alfonso': 2, 'signorini': 2, 'totti': 2, 'scritto': 2, 'solo': 2, 'arrivato': 2, 'stata': 1, 'fiordelisi': 1, 'concorrente': 1, 'grande': 1, 'fratello': 1, 'vip': 1, 'lanciare': 1, 'bomba': 1, 'corso': 1, 'ultima': 1, 'puntata': 1, 'reality': 1, 'show': 1, 'condotto': 1, 'mandato': 1, 'ciao': 1, 'accaduto': 1, 'qualche': 1, 'mese': 1, 'fa': 1, 'raccontato': 1, 'influencer': 1, 'lanciando': 1, 'assist': 1, 'conduttore': 1, 'sottolineato': 1, 'fatto': 1, 'tempi': 1, 'raccontati': 1, 'corrispondessero': 1, 'vero': 1, 'quando': 1, 'ex': 1, 'capitano': 1, 'roma': 1, 'già': 1, 'legato': 1, 'noemi': 1, 'bocchi': 1, 'difendere': 1, 'amico': 1, 'alex': 1, 'nuccetelli': 1, 'secondo': 1, 'quel': 1, 'stato': 1, 'frutto': 1, 'fraintendimento': 1})\n"
     ]
    }
   ],
   "source": [
    "def pulizia(testo):\n",
    "    testo = testo.lower()  # se vogliamo lasciare i nomi in maiuscolo, va fatto qui\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    testo = tokenizer.tokenize(testo) # remove punctuatiton\n",
    "\n",
    "    filtered_testo = [w for w in testo if not w in stop_words]\n",
    "\n",
    "    return(filtered_testo)\n",
    "\n",
    "#filtered_sentence\n",
    "\n",
    "print(pulizia(testo1))\n",
    "print('*************'*12)\n",
    "print('*************'*12)\n",
    "print(Counter(pulizia(testo1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['totti', 'roma']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'Totti Roma'.lower().split()\n",
    "query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ho trovato una corrispondenza perfetta con il testo 1\n",
      "Testo 1 ha un punteggio di 1\n"
     ]
    }
   ],
   "source": [
    "text = [testo1, testo2, testo3, testo4, testo5, testo6]\n",
    "\n",
    "\n",
    "#query = input().split()\n",
    "\n",
    "for i in range(len(text)):\n",
    "    if all(words in text[i] for words in query):\n",
    "        print('Ho trovato una corrispondenza perfetta con il testo', i+1)\n",
    "        print('Testo', i+1, 'ha un punteggio di', 1)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Totti' in testo1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['È',\n",
       " 'stata',\n",
       " 'Antonella',\n",
       " 'Fiordelisi,',\n",
       " 'concorrente',\n",
       " 'del',\n",
       " 'Grande',\n",
       " 'Fratello',\n",
       " 'Vip.',\n",
       " 'A',\n",
       " 'lanciare',\n",
       " 'una',\n",
       " 'bomba',\n",
       " 'nel',\n",
       " 'corso',\n",
       " 'dell’ultima',\n",
       " 'puntata',\n",
       " 'del',\n",
       " 'reality',\n",
       " 'show',\n",
       " 'condotto',\n",
       " 'da',\n",
       " 'Alfonso',\n",
       " 'Signorini.',\n",
       " '“Totti',\n",
       " 'mi',\n",
       " 'ha',\n",
       " 'scritto,',\n",
       " 'mi',\n",
       " 'ha',\n",
       " 'mandato',\n",
       " 'solo',\n",
       " 'un',\n",
       " 'messaggio.Aveva',\n",
       " 'scritto',\n",
       " '‘Ciao’.',\n",
       " 'È',\n",
       " 'accaduto',\n",
       " 'qualche',\n",
       " 'mese',\n",
       " 'fa”,',\n",
       " 'ha',\n",
       " 'raccontato',\n",
       " 'l’influencer,',\n",
       " 'lanciando',\n",
       " 'un',\n",
       " 'assist',\n",
       " 'al',\n",
       " 'conduttore',\n",
       " 'Alfonso',\n",
       " 'Signorini',\n",
       " 'che',\n",
       " 'ha',\n",
       " 'sottolineato',\n",
       " 'il',\n",
       " 'fatto',\n",
       " 'che,',\n",
       " 'se',\n",
       " 'i',\n",
       " 'tempi',\n",
       " 'raccontati',\n",
       " 'da',\n",
       " 'Antonella',\n",
       " 'corrispondessero',\n",
       " 'al',\n",
       " 'vero,',\n",
       " 'il',\n",
       " 'messaggio',\n",
       " 'sarebbe',\n",
       " 'arrivato',\n",
       " 'quando',\n",
       " 'l’ex',\n",
       " 'capitano',\n",
       " 'della',\n",
       " 'Roma',\n",
       " 'era',\n",
       " 'già',\n",
       " 'legato',\n",
       " 'a',\n",
       " 'Noemi',\n",
       " 'Bocchi.',\n",
       " 'A',\n",
       " 'difendere',\n",
       " 'Totti',\n",
       " 'è',\n",
       " 'arrivato',\n",
       " 'l’amico',\n",
       " 'Alex',\n",
       " 'Nuccetelli',\n",
       " 'secondo',\n",
       " 'il',\n",
       " 'quale',\n",
       " 'quel',\n",
       " 'messaggio',\n",
       " 'sarebbe',\n",
       " 'stato',\n",
       " 'solo',\n",
       " 'il',\n",
       " 'frutto',\n",
       " 'di',\n",
       " 'un',\n",
       " 'fraintendimento']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testo1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8922abe8a2f354f864dd8097bc99cbc9988d6260d5a3250d7fc0c8c4274840cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
