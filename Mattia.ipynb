{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01ba3847-a73c-4ad2-9635-95e87a04abd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Homework 3 - Places of the world"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5ca2b4-9abf-4ce9-8c21-38cd2080cf60",
   "metadata": {},
   "source": [
    "## Libriaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a2ad83-0386-4aff-8ebc-52f83d38edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup \n",
    "import requests\n",
    "import re\n",
    "import urllib.request\n",
    "import os\n",
    "from time import perf_counter\n",
    "from clear_cache import clear as clean_cache\n",
    "import multiprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26335054-8e94-4ef7-bd76-6c593257bcc0",
   "metadata": {},
   "source": [
    "### 1. Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4bf5a1-f1fd-4d28-a47c-8f9ef646eea5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.1. Get the list of places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44ffe2b-c30f-41e7-9a75-67a160282e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"urls.txt\", \"w\")\n",
    "\n",
    "for i in range(1,401):\n",
    "    url = f'https://www.atlasobscura.com/places?page={i}&sort=likes_count'\n",
    "    reqs = requests.get(url)\n",
    "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "    for link in soup.find_all(class_=re.compile(\"content-card content-card-place\")):\n",
    "        a=(link.get('href'))\n",
    "        f.write('https://www.atlasobscura.com/'+a)\n",
    "        f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16452c4-5736-48c6-9bef-c756e31c01e6",
   "metadata": {},
   "source": [
    "#### 1.2. Crawl places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd88715-6919-4714-8015-e8d1bdf80631",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def download(a):\n",
    "    times_={}\n",
    "    for i in range(1,401):\n",
    "        url = f'https://www.atlasobscura.com/places?page={i}&sort=likes_count'\n",
    "       perf_counterrt_time = perf_counter()\n",
    "        reqs = requests.get(url)\n",
    "        soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "        os.makedirs('PAGE '+str(i))\n",
    "        os.chdir('PAGE '+str(i))\n",
    "        count=i\n",
    "        for link in soup.find_all(class_=re.compile(\"content-card content-card-place\")):\n",
    "            a=(link.get('href'))\n",
    "            url_='https://www.atlasobscura.com/'+a\n",
    "            file= open(str(a)[8:]+'.html','w',encoding=\"UTF-8\")\n",
    "            with urlopen( url_ ) as webpage:\n",
    "                content = webpage.read().decode()\n",
    "            file.write(content)\n",
    "            file.close()\n",
    "        end_time = perf_counter()\n",
    "        final_time = end_time - start_time\n",
    "        if count not in times:\n",
    "            times_[count]=final_time\n",
    "        os.chdir('..')\n",
    "        clean_cache()\n",
    "\n",
    "N = multiprocessing.cpu_count()*2\n",
    "with multiprocessing.Pool(processes=N) as pool:\n",
    "     pool.map(download('urls.txt'),range(100))\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e540a306-b1fc-489c-ae6d-1cb291f3c374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\matti\\\\OneDrive\\\\Desktop\\\\ADM\\\\REPO\\\\Homework-3'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d6a1c1-5aba-49b8-a7cb-851865ae4f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "times={}\n",
    "for i in range(1,101):\n",
    "        url = f'https://www.atlasobscura.com/places?page={i}&sort=likes_count'\n",
    "        start_time = perf_counter()\n",
    "        reqs = requests.get(url)\n",
    "        soup = BeautifulSoup(reqs.text, 'html.parser')\n",
    "        os.makedirs('PAGE '+str(i))\n",
    "        os.chdir('PAGE '+str(i))\n",
    "        count=i\n",
    "        for link in soup.find_all(class_=re.compile(\"content-card content-card-place\")):\n",
    "            a=(link.get('href'))\n",
    "            url_='https://www.atlasobscura.com/'+a\n",
    "            file= open(str(a)[8:]+'.html','w',encoding=\"UTF-8\")\n",
    "            with urlopen( url_ ) as webpage:\n",
    "                content = webpage.read().decode()\n",
    "            file.write(content)\n",
    "            file.close()\n",
    "        end_time = perf_counter()\n",
    "        final_time = end_time - start_time\n",
    "        if count not in times:\n",
    "            times[count]=final_time\n",
    "        os.chdir('..')\n",
    "        clean_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57191a38-3263-41b8-8c87-0a473cf681ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 47.217420000000004, 2: 81.355642}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f5625e-d988-44a3-af32-0a617d503de5",
   "metadata": {},
   "source": [
    "#### 1.3 Parse downloaded pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679594bd-4261-4f4b-9ef5-c4a937a38a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,401):\n",
    "    os.chdir('PAGE '+str(i))\n",
    "    for filename in os.listdir(os.getcwd()):\n",
    "        if filename.endswith(\".html\"):\n",
    "            with open(os.path.join(os.getcwd(), filename), 'r',encoding='utf-8') as f:\n",
    "                soup = BeautifulSoup(f,'html.parser')\n",
    "                out=[]\n",
    "                tag=[]\n",
    "\n",
    "\n",
    "\n",
    "                [out.append(i.text) for i in soup.find_all(class_=re.compile(\"DDPage__header-title\"))]\n",
    "                [tag.append(i.text[1:-1]) for i in soup.find_all(class_=re.compile(\"itemTags__link js-item-tags-link\"))]\n",
    "                out.append(tag)\n",
    "                a=[int(i.text) for i in soup.find_all(class_=re.compile(\"title-md item-action-count\"))]\n",
    "                out.append(a[0])\n",
    "                out.append(a[1])\n",
    "                [out.append(i.text.replace('\\n',' ')[2:-2]) for i in soup.find_all(class_=re.compile(\"DDP__body-copy\"))]\n",
    "                [out.append(i.text[:-1]) for i in soup.find_all(class_=re.compile(\"DDPage__header-dek\"))]\n",
    "                b=[(i.text.replace('\\n',' ')[1:-1]) for i in soup.find_all(class_=re.compile(\"DDPageSiderailRecirc__item-text\"))]\n",
    "                out.append(b)\n",
    "                [out.append(i.text.replace('\\n','')) for i in soup.select('#place-container > div.DDPage__content-row.grid-row > div.DDPageSiderail__column.grid-col-lg-4.grid-col-md-5 > div.DDPageSiderail > aside.DDPageSiderail__details > address > div')]\n",
    "                c=[(i.text.replace('\\n','').split(',')) for i in soup.select('#place-container > div.DDPage__content-row.grid-row > div.DDPageSiderail__column.grid-col-lg-4.grid-col-md-5 > div.DDPageSiderail > aside.DDPageSiderail__details > div')]\n",
    "                out.append(float(c[0][0]))\n",
    "                out.append(float(c[0][1]))\n",
    "                cont=[]\n",
    "                [cont.append(i.text) for i in soup.select('#ugc-module > div > div:nth-child(2) > div.DDPContributorsList > a')]\n",
    "                [cont.append(i.string) for i in soup.select('li>a>span') if i.string!=None]\n",
    "                out.append(cont) \n",
    "                for i in soup.find_all(class_=re.compile('DDPContributor__name')):\n",
    "                    time=(i.text.replace(',',''))\n",
    "                if isinstance(a,str)==True:\n",
    "                    time=(datetime.strptime(time,'%B %d %Y').date())\n",
    "                    out.append(time)\n",
    "                else:\n",
    "                    out.append(time)\n",
    "                lists=[]\n",
    "                [lists.append(i.text) for i in (soup.select('#page-content > article > div.vue-js-bte-place-parent.hidden-print.js-vue-component-wrap > div:nth-child(6) > div > div > div.card-grid.CardRecircSection__card-grid.js-inject-gtm-data-in-child-links>div>div>a>div>h3>span'))]\n",
    "                out.append(lists)\n",
    "                rel=[]\n",
    "                [rel.append(i.text) for i in (soup.select('#page-content > article > div.vue-js-bte-place-parent.hidden-print.js-vue-component-wrap > div:nth-child(4) > div > div > div.card-grid.CardRecircSection__card-grid.js-inject-gtm-data-in-child-links>div>div>a>div>h3>span'))]\n",
    "                out.append(rel)\n",
    "                out.append(soup.find('link',{'rel':'canonical'})['href'])\n",
    "\n",
    "                f.close()\n",
    "                l = ['placeName','placeTags','numPeopleVisited','numPeopleWant','placeDesc','placeShortDesc','placeNearby','placeAddress','placeAlt',\n",
    "                    'placeLong','placeEditors','placePubDate','placeRelatedLists','placeRelatedPlaces','placeURL']\n",
    "                with open(filename+'.tsv','w',encoding='utf-8') as tsv:\n",
    "                    tsv_output = csv.writer(tsv, delimiter='\\t')\n",
    "                    tsv_output.writerow(l)\n",
    "                    tsv_output.writerow(out)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c650373d-f92f-4a15-834a-c3d4a9be9fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "for i in range(1,401):\n",
    "    os.chdir('PAGE '+str(i))\n",
    "    for filename in os.listdir(os.getcwd()):\n",
    "        if filename.endswith(\".tsv\"):\n",
    "            a = pd.read_csv(filename,sep='\\t')\n",
    "            data.append(a)\n",
    "    os.chdir('..')\n",
    "data=pd.concat(data,ignore_index=True)     \n",
    "data.to_csv('Dataset.tsv',sep='\\t',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e49e9-8506-4b12-8611-8c6ddf2f50c7",
   "metadata": {},
   "source": [
    "### HASHING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca9c3088-7668-43ce-bcdc-45a767819506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "729fd781-6a0f-4c8a-be83-b4ce8d478e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f857c734-31e4-4ebe-b737-8228e9ad3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=['Mattia','museum','american',]\n",
    "vec=HashingVectorizer(n_features=2**4)\n",
    "x=vec.fit_transform(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b850b3a-f7a7-443c-9c4b-04550642d323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fec2657-ee5f-4e94-bb0f-de6d7a92314b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
